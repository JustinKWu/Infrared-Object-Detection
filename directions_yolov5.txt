
Tasks:
1. Train the baseline network on any desktop or laptop computer, and assess its performance on the test set. This will serve as your baseline performance for accuracy.
2. Implement the test code on the Xavier processor, and obtain the performance accuracy as well as the time required to process the test images
3. 
	A. Optimize the trained network model such that the processing time is decreased by a factor of two. 
	   What is the resulting performance accuracy? What is the equivalent frames/second (FPS)?
	B. What accuracy can you achieve if the system must operate at 10 FPS?
4. Characterize the power consumption as a function of FPS and accuracy..

Comparitive Study:
- Take 640 by 640 (or 448 by 448) trained model and test it using a smaller image size like 448 by 448 (or 224 by 224)

GIT Repo:
Yolov5 (https://github.com/ultralytics/yolov5)
Infared-Object-Detection (https://github.com/Wutang123/Infrared-Object-Detection)

Image Sizes:
1. 224x224 (224/32 = 7)
2. 448x448 (448/32 = 14)
3. 640x640 (640/32 = 20)

Hyperparamters:
- hyp.scratch.yaml

Baseline Average Power Consumption: 
- CPU, GPU, CV: 577 mW 
- SOC: 689 mW 
- ALL: 2765 mW
------------------------------Commands to use:--------------------------

Training (PC)
python train.py --weights yolov5s.pt --data .\data\flir.yaml --epoch 100 --batch-size 16 --workers 4 --img-size 224
python train.py --weights yolov5s.pt --data .\data\flir.yaml --epoch 100 --batch-size 16 --workers 4 --img-size 448
python train.py --weights yolov5s.pt --data .\data\flir.yaml --epoch 100 --batch-size 16 --workers 4 --img-size 640



Testing (PC)
python val.py --weights .\runs\train\exp\weights\best.pt --data .\data\flir.yaml --batch-size 16 --img-size 224
python val.py --weights .\runs\train\exp\weights\best.pt --data .\data\flir.yaml --batch-size 16 --img-size 224 --half
python val.py --weights .\runs\train\exp2\weights\best.pt --data .\data\flir.yaml --batch-size 16 --img-size 448
python val.py --weights .\runs\train\exp2\weights\best.pt --data .\data\flir.yaml --batch-size 16 --img-size 448 --half
python val.py --weights .\runs\train\exp3\weights\best.pt --data .\data\flir.yaml --batch-size 16 --img-size 640
python val.py --weights .\runs\train\exp3\weights\best.pt --data .\data\flir.yaml --batch-size 16 --img-size 640 --half

Testing(Xavier)
python3 val.py --weights pt/exp/best.pt --data data/flir.yaml --batch-size 16 --img-size 224
python3 val.py --weights pt/exp/best.pt --data data/flir.yaml --batch-size 16 --img-size 224 --half
python3 val.py --weights pt/exp2/best.pt --data data/flir.yaml --batch-size 16 --img-size 448
python3 val.py --weights pt/exp2/best.pt --data data/flir.yaml --batch-size 16 --img-size 448 --half
python3 val.py --weights pt/exp3/best.pt --data data/flir.yaml --batch-size 16 --img-size 640
python3 val.py --weights pt/exp3/best.pt --data data/flir.yaml --batch-size 16 --img-size 640 --half



Detect (PC)
python detect.py --weights .\runs\train\exp\weights\best.pt --source .\data\flir\images\test --img-size 224
python detect.py --weights .\runs\train\exp\weights\best.pt --source .\data\flir\images\test --img-size 224 --half
python detect.py --weights .\runs\train\exp2\weights\best.pt --source .\data\flir\images\test --img-size 448
python detect.py --weights .\runs\train\exp2\weights\best.pt --source .\data\flir\images\test --img-size 448 --half
python detect.py --weights .\runs\train\exp3\weights\best.pt --source .\data\flir\images\test --img-size 640
python detect.py --weights .\runs\train\exp3\weights\best.pt --source .\data\flir\images\test --img-size 640 --half

Detect (Xavier)
python3 detect.py --weights pt/exp/best.pt --source data/flir/images/test/ --img-size 224
python3 detect.py --weights pt/exp/best.pt --source data/flir/images/test/ --img-size 224 --half
python3 detect.py --weights pt/exp2/best.pt --source data/flir/images/test/ --img-size 448
python3 detect.py --weights pt/exp2/best.pt --source data/flir/images/test/ --img-size 448 --half
python3 detect.py --weights pt/exp3/best.pt --source data/flir/images/test/ --img-size 640
python3 detect.py --weights pt/exp3/best.pt --source data/flir/images/test/ --img-size 640 --half

Study
python val.py --weights .\runs\train\exp\weights\best.pt --data .\data\flir.yaml --batch-size 2 --img-size 224 --task study

TensorRT (Xavier) (See https://github.com/wang-xinyu/tensorrtx/tree/master/yolov5 for more directions)
- yolov5 directory
- Generates the .pt to .wts
python3 gen_wts.py -w pt/exp/best.pt -o pt/exp/best1.wts
python3 gen_wts.py -w pt/exp2/best.pt -o pt/exp2/best2.wts
python3 gen_wts.py -w pt/exp3/best.pt -o pt/exp3/best3.wts
cp pt/exp/best1.wts ../tensorrtx/yolov5/build
cp pt/exp2/best2.wts ../tensorrtx/yolov5/build
cp pt/exp3/best3.wts ../tensorrtx/yolov5/build

- tensorrtx/yolov5 directory
- Verify the images size in yololayer.h matches the one you're going to test
- Verify Use_FP16/Use_FP32 is set in yolov5.cpp (FP32 first then FP16)

- tensorrtx/yolov5/build directory
make
sudo ./yolov5 -s best1.wts best1.engine s
sudo ./yolov5 -s best2.wts best2.engine s
sudo ./yolov5 -s best3.wts best3.engine s

- ../samples should have all the images from .\data\flir\images\test
- Test FP32 first the FP16, *****Need to do make whenever you change the .cpp or .h file*****
- Copy all the inference times in a .csv file
- Average the times
- Record value
sudo ./yolov5 -d best1.engine ../samples
sudo ./yolov5 -d best2.engine ../samples
sudo ./yolov5 -d best3.engine ../samples

- Move all the generated files to (runs/tensorrt/exp*/)
mv _FLIR_* runs/tensorrt/exp*/

Plots
python
from utils.plots import plot_results 
plot_results(save_dir='runs/train/exp')

------------------------------train.py--------------------------
Training (PC) exp ***DONE***
- 224 by 224
- 100 epochs
- yolov5s
- batch 16
- workers 4
- hyper.scratch.yaml
- 8 bit unannotated flir 
- 1.081 hours 
- 283 layers
- 7276605 parameters
- 7276605 gradients
- 17.1 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.587      0.361      0.345      0.155
person    1363       5014      0.728      0.424      0.502      0.196
bicycle   1363       350       0.471      0.289      0.231      0.087
car       1363       4247      0.65       0.656      0.57       0.331
dog       1363       13        0.5        0.0769     0.0763     0.00773


Training (PC) exp2 ***DONE***
- 448 by 448
- 100 epochs
- yolov5s
- batch 16
- workers 4
- hyper.scratch.yaml
- 8 bit unannotated flir 
- 1.853 hours 
- 283 layers
- 7276605 parameters
- 7276605 gradients
- 17.1 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.639      0.56       0.522      0.268
person    1363       5014      0.763      0.665      0.716      0.347
bicycle   1363       350       0.601      0.525      0.418      0.157
car       1363       4247      0.69       0.821      0.697      0.448
dog       1363       13        0.502      0.231      0.259      0.122

Training (PC) exp3 ***DONE***
- 640 by 640
- 100 epochs
- yolov5s
- batch 16
- workers 4
- hyper.scratch.yaml
- 8 bit unannotated flir 
- 2.844 hours 
- 283 layers
- 7276605 parameters
- 7276605 gradients
- 17.1 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.661      0.598      0.527       0.27
person    1363       5014      0.733      0.734      0.737      0.359
bicycle   1363       350       0.533      0.569      0.432      0.164
car       1363       4247      0.638      0.866      0.707      0.451
dog       1363       13        0.741      0.223      0.231      0.104

------------------------------val.py:--------------------------

############## 224 x 224 ##############
Test(PC) exp ***DONE***
- exp\weights\best.pt
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.0 ms
- Inference: 0.8 ms 
- 1.2 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.585      0.361      0.345      0.156

Test(PC) exp2 ***DONE***
- exp\weights\best.pt
- --half
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.0 ms
- Inference: 0.6 ms 
- 1.2 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.582      0.362      0.345      0.155

Test(Xavier) exp ***DONE***
- pt/exp/best.pt
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference:  9.8 ms 
- 4.1 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.588      0.361      0.345      0.156

Test(Xavier) exp2 ***DONE***
- pt/exp/best.pt
- --half
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 6.6 ms 
- 3.5 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.583      0.362      0.345      0.155
  
  
############## 448 x 448 ##############
Test(PC) exp3 ***DONE***
- exp2\weights\best.pt
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 2.1 ms 
- 1.0 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.637       0.56      0.524       0.27

Test(PC) exp4 ***DONE***
- exp2\weights\best.pt
- --half
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 1.3 ms 
- 1.0 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.639       0.56      0.522      0.268

Test(Xavier) exp3 ***DONE***
- pt/exp2/best.pt
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.3 ms
- Inference: 26.6 ms 
- 4.3 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.639       0.56      0.524       0.27

Test(Xavier) exp4 ***DONE***
- pt/exp2/best.pt
- --half
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.2 ms
- Inference: 16.3 ms 
- 4.4 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.638      0.562      0.523      0.269


############## 640 x 640 ##############
Test(PC) exp5 ***DONE***
- exp3\weights\best.pt
- 640 by 640
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 3.9 ms 
- 1.2 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOP
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.658      0.602      0.528       0.27

Test(PC) exp6 ***DONE***
- exp3\weights\best.pt
- --half
- 640 by 640
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 2.3 ms 
- 1.3 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.658      0.602      0.527       0.27

==================================OPTIMIZER=======================================
Test(PC) exp7 ***DONE***
- exp3\weights\best.pt
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 2.1 ms 
- 1.1 ms NMS per image at shape (16,3,480,480)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.482      0.482      0.447      0.224

Test(PC) exp8 ***DONE***
- exp3\weights\best.pt
- --half
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 1.3 ms 
- 1.1 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.481       0.48      0.445      0.223

Test(PC) exp9 ***DONE***
- exp3\weights\best.pt
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.0 ms
- Inference: 0.7 ms 
- 1.1 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.432      0.342      0.281      0.124

Test(PC) exp10 ***DONE***
- exp3\weights\best.pt
- --half
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.0 ms
- Inference: 0.6 ms 
- 1.2 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.433       0.34      0.281      0.124
==================================         =======================================
 
Test(Xavier) exp5 ***DONE***
- pt/exp3/best.pt
- 640 by 640
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.5 ms
- Inference: 52.0 ms 
- 4.9 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
- Average Power Consumption:
	- CPU, GPU, CV: 4000 mW 
	- SOC: 	        1753 mW 
	- ALL: 	        8600 mW
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.658      0.602      0.528       0.27

Test(Xavier) exp6 ***DONE***
- pt/exp3/best.pt
- --half
- 640 by 640
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.4 ms
- Inference: 31.8 ms 
- 5.0 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
- Average Power Consumption:
	- CPU, GPU, CV: 4000 mW 
	- SOC: 	        1700 mW 
	- ALL: 	        8200 mW
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.658      0.603      0.528       0.27

==================================OPTIMIZER=======================================
Test(Xavier) exp7 ***DONE***
- pt/exp3/best.pt
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.3 ms
- Inference: 26.5 ms 
- 5.1 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
- Average Power Consumption:
	- CPU, GPU, CV: 3900 mW 
	- SOC: 	        1600 mW 
	- ALL: 	        8000 mW
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.484       0.48      0.447      0.224

Test(Xavier) exp8 ***DONE***
- pt/exp3/best.pt
- --half
- 448 by 448
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.2 ms
- Inference: 16.1 ms 
- 4.7 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
- Average Power Consumption:
	- CPU, GPU, CV: 3800 mW 
	- SOC: 	        1500 mW 
	- ALL: 	        8000 mW
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.481       0.48      0.445      0.223

Test(Xavier) exp9 ***DONE***
- pt/exp3/best.pt
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 10.2 ms 
- 3.2 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
- Average Power Consumption:
	- CPU, GPU, CV: 3800 mW 
	- SOC: 	        1500 mW 
	- ALL: 	        8000 mW
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.433       0.34      0.281      0.124

Test(Xavier) exp10 ***DONE***
- pt/exp3/best.pt
- --half
- 224 by 224
- yolov5s
- batch 16
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.1 ms
- Inference: 6.7 ms 
- 3.1 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs
- Average Power Consumption:
	- CPU, GPU, CV: 3500 mW 
	- SOC: 	        1300 mW 
	- ALL: 	        7500 mW
Class     Images     Labels      P          R        mAP@.5   mAP@.5:.95
all       1363       9624      0.433       0.34      0.281      0.124
==================================         =======================================

------------------------------detect.py:--------------------------

############## 224 x 224 ##############
Detect(PC) exp ***DONE***
- exp\weights\best.pt
- 224 by 224
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.3 ms
- Inference: 8.1 ms 
- 1.0 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(PC) exp2 ***DONE***
- exp\weights\best.pt
- --half
- 224 by 224
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.3 ms
- Inference: 8.0 ms 
- 1.0 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(Xavier) exp ***DONE***
- pt/exp/best.pt
- 224 by 224
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 1.0 ms
- Inference: 22.8 ms 
- 2.7 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(Xavier) exp2 ***DONE***
- pt/exp/best.pt
- --half
- 224 by 224
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 1.1 ms
- Inference: 28.9 ms 
- 2.6 ms NMS per image at shape (16,3,224,224)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs


############## 448 x 448 ##############
Detect(PC) exp3 ***DONE***
- exp2\weights\best.pt
- 448 by 448
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.4 ms
- Inference: 7.9 ms 
- 1.0 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(PC) exp4 ***DONE***
- exp2\weights\best.pt
- --half
- 448 by 448
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.4 ms
- Inference: 7.7 ms 
- 1.1 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(Xavier) exp3 ***DONE***
- pt/exp2/best.pt
- 448 by 448
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 1.1 ms
- Inference: 37.2 ms 
- 3.1 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(Xavier) exp4 ***DONE***
- pt/exp2/best.pt
- --half
- 448 by 448
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 1.1 ms
- Inference: 33.0 ms 
- 2.6 ms NMS per image at shape (16,3,448,448)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs


############## 640 x 640 ##############
Detect(PC) exp5 ***DONE***
- exp3\weights\best.pt
- 640 by 640
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.4 ms
- Inference: 7.7 ms 
- 1.0 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(PC) exp6 ***DONE***
- exp3\weights\best.pt
- --half
- 640 by 640
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 0.4 ms
- Inference: 7.7 ms 
- 1.0 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(Xavier) exp5 ***DONE***
- pt/exp3/best.pt
- 640 by 640
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 1.4 ms
- Inference: 61.2 ms 
- 3.4 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

Detect(Xavier) exp6 ***DONE***
- pt/exp3/best.pt
- --half
- 640 by 640
- yolov5s
- 8 bit unannotated flir (test dataset)
- Pre-process: 1.3 ms
- Inference: 38.7 ms 
- 3.1 ms NMS per image at shape (16,3,640,640)
- 224 layers
- 7266973 parameters
- 0 gradients
- 17.0 GFLOPs

------------------------------TensorRT:--------------------------
############## 224 x 224 ##############
TensorRT (Xavier) exp ***DONE***
- pt/exp/best.pt (best1.wts)
- runs/tensorrt/exp/
- 8 bit unannotated flir (test dataset)
- FP32
- Average: 20.43 ms

TensorRT (Xavier) exp2 ***DONE***
- pt/exp/best.pt (best1.wts)
- runs/tensorrt/exp2/
- 8 bit unannotated flir (test dataset)
- FP16
- Average: 8.47 ms


############## 448 x 448 ##############
TensorRT (Xavier) exp3 ***DONE***
- pt/exp2/best.pt (best2.wts)
- runs/tensorrt/exp3/
- 8 bit unannotated flir (test dataset)
- FP32
- Average: 31.03 ms

TensorRT (Xavier) exp4 ***DONE***
- pt/exp2/best.pt (best2.wts)
- runs/tensorrt/exp4/
- 8 bit unannotated flir (test dataset)
- FP16
- Average: 20.98 ms

############## 640 x 640 ##############
TensorRT (Xavier) exp5 ***DONE***
- pt/exp3/best.pt (best3.wts)
- runs/tensorrt/exp5/
- 8 bit unannotated flir (test dataset)
- FP32
- Average: 56.09 ms

TensorRT (Xavier) exp6 ***DONE***
- pt/exp3/best.pt (best3.wts)
- runs/tensorrt/exp6/
- 8 bit unannotated flir (test dataset)
- FP16
- Average: 21.76 ms
